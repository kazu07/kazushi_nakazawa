<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="Kazushi Nakazawa is an AI engineer. Explore publications, career history, and awards." />
  <meta name="author" content="Kazushi Nakazawa" />
  <meta property="og:title" content="Kazushi Nakazawa | AI Engineer" />
  <meta property="og:description" content="Research portfolio of Kazushi Nakazawa." />
  <meta property="og:type" content="website" />
  <meta property="og:locale" content="ja_JP" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Kazushi Nakazawa | AI Engineer" />
  <meta name="twitter:description" content="Research portfolio of Kazushi Nakazawa." />
  <title>Kazushi Nakazawa | AI Engineer</title>
  <link rel="stylesheet" href="styles.css" />
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Person",
    "name": "Kazushi Nakazawa",
    "email": "mailto:kazu0304v@gmail.com",
    "jobTitle": "AI Engineer",
    "affiliation": [
      {
        "@type": "Organization",
        "name": "Advanced Media, Inc."
      },
      {
        "@type": "CollegeOrUniversity",
        "name": "Yamagata University"
      }
    ],
    "alumniOf": {
      "@type": "CollegeOrUniversity",
      "name": "Yamagata University"
    },
    "knowsAbout": [
      "Speech intelligibility estimation",
      "Speech enhancement",
      "Audio quality assessment"
    ]
  }
  </script>
</head>
<body>
  <header>
    <h1><strong>Kazushi Nakazawa</strong></h1>
    <p>Research Portfolio</p>
    <p>Email: <a href="mailto:kazu0304v@gmail.com">kazu0304v@gmail.com</a></p>
    <div class="social-links" aria-label="Social links">
      <a href="https://x.com/nkzwkzs" target="_blank" rel="noopener noreferrer" aria-label="Follow on X (Twitter)">
        <svg viewBox="0 0 24 24" aria-hidden="true">
          <path d="M18.244 3H21.5l-7.37 8.41L22 21h-6.09l-4.78-6.24L5.6 21H2.34l7.89-9L2 3h6.21l4.33 5.79L18.244 3zm-1.07 16h1.69L7.91 4.98H6.09l11.084 14.02z" />
        </svg>
        <span class="sr-only">X (Twitter)</span>
      </a>
      <a href="https://www.linkedin.com/in/kazushi-nakazawa-2a2901164/" target="_blank" rel="noopener noreferrer" aria-label="Connect on LinkedIn">
        <svg viewBox="0 0 24 24" aria-hidden="true">
          <path d="M4.98 3.5C4.98 4.88 3.86 6 2.5 6S0 4.88 0 3.5 1.12 1 2.5 1 4.98 2.12 4.98 3.5zM0 8.98h5V24H0zM8.47 8.98h4.78v2.05h.07c.66-1.24 2.27-2.54 4.67-2.54 5 0 5.92 3.3 5.92 7.59V24h-5v-6.89c0-1.64-.03-3.74-2.28-3.74-2.28 0-2.63 1.78-2.63 3.62V24h-5z" />
        </svg>
        <span class="sr-only">LinkedIn</span>
      </a>
      <a href="https://github.com/kazu07" target="_blank" rel="noopener noreferrer" aria-label="View GitHub profile">
        <svg viewBox="0 0 24 24" aria-hidden="true">
          <path d="M12 .5C5.73.5.5 5.74.5 12.02c0 5.1 3.3 9.43 7.88 10.96.58.11.79-.25.79-.56 0-.27-.01-1.17-.02-2.12-3.21.7-3.89-1.39-3.89-1.39-.53-1.35-1.3-1.71-1.3-1.71-1.06-.73.08-.72.08-.72 1.17.08 1.79 1.2 1.79 1.2 1.04 1.79 2.74 1.27 3.41.97.11-.76.41-1.27.75-1.56-2.56-.29-5.26-1.29-5.26-5.73 0-1.27.45-2.31 1.2-3.13-.12-.29-.52-1.46.11-3.04 0 0 .97-.31 3.18 1.19a11.1 11.1 0 0 1 2.9-.39c.99 0 1.99.13 2.9.39 2.21-1.5 3.18-1.19 3.18-1.19.63 1.58.23 2.75.11 3.04.75.82 1.2 1.86 1.2 3.13 0 4.46-2.71 5.43-5.29 5.72.42.36.8 1.07.8 2.16 0 1.56-.02 2.82-.02 3.2 0 .31.21.68.79.56 4.58-1.53 7.88-5.86 7.88-10.96C23.5 5.74 18.27.5 12 .5z" />
        </svg>
        <span class="sr-only">GitHub</span>
      </a>
    </div>
  </header>
  <main>
    <section>
      <h2>Career</h2>
      <ul class="item-list">
        <li>
          <span class="item-title">[Apr 2024 - Present] AI Engineer</span>
          <span class="item-meta">Advanced Media, Inc., Tokyo, Japan</span>
        </li>
        <li>
          <span class="item-title">[Oct 2023 - Mar 2024] AI Engineer Intern</span>
          <span class="item-meta">Ghelia Inc., Tokyo, Japan</span>
        </li>
        <li>
          <span class="item-title">[Aug 2021 - Sep 2021] Research Intern</span>
          <span class="item-meta">NTT, Tokyo, Japan</span>
        </li>
        <li>
          <span class="item-title">[Apr 2020 - Sep 2023] Ph.D. Candidate, Electronics and Information Engineering</span>
          <span class="item-meta">Graduate School of Science and Engineering, Yamagata University, Yamagata, Japan</span>
        </li>
        <li>
          <span class="item-title">[Apr 2018 - Mar 2020] M.S. Student, Electrical and Electronic Engineering</span>
          <span class="item-meta">Graduate School of Science and Engineering, Yamagata University, Yamagata, Japan</span>
        </li>
        <li>
          <span class="item-title">[Apr 2014 - Mar 2018] B.Eng. Student, Electrical and Electronic Engineering</span>
          <span class="item-meta">Faculty of Engineering, Yamagata University, Yonezawa, Japan</span>
        </li>
      </ul>
    </section>

    <section>
      <h2>Research Achievements</h2>
      <div class="research-group">
        <h3>Journal Articles</h3>
        <ol>
          <li><strong>中澤和司</strong>, 近藤和弘. 残響劣化した音声に対するノンレファレンス音声了解度推定における推定精度向上. 電気学会論文誌C（電子・情報・システム部門誌）, Vol. 143, No. 8, pp. 830-841, 2023.</li>
        </ol>
      </div>

      <div class="research-group">
        <h3>International Conferences</h3>
        <ol>
          <li><strong>Kazushi Nakazawa</strong> and Kazuhiro Kondo, "Non-Intrusive Speech Intelligibility Prediction of Speech With Additive Noise and Reverberation Using Multiple Deep Learning-Based Speech Enhancement," in 2023 IEEE 12th Global Conference on Consumer Electronics (GCCE), Nara, Japan, 2023/10.</li>
          <li><strong>Kazushi Nakazawa</strong> and Kazuhiro Kondo, "Non-intrusive speech intelligibility prediction method for reverberant speech using neural network-based frequency segmentation and masking front-end," in Inter-Noise 2023, Chiba, Japan, 2023/8.</li>
          <li><strong>Kazushi Nakazawa</strong> and Kazuhiro Kondo, "Non-intrusive speech intelligibility estimation using deep learning with speech enhancement and convolutional layers," in 2022 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Chiang Mai, Thailand, 2022/11, pp. 1047-1052.</li>
          <li><strong>Kazushi Nakazawa</strong> and Kazuhiro Kondo, "Improving the accuracy of non-intrusive intelligibility estimation for reverberant speech using speech enhancement by optimizing the speech feature parameters," in Proceedings of the 24th International Congress on Acoustics, Gyeongju, South Korea, 2022/10, p. ABS-0721.</li>
          <li>Toya Kitagawa, Kazuhiro Kondo, <strong>Kazushi Nakazawa</strong>, Sara Asai, "Evaluation of Home Appliance Speakers with Correction Filters for Voice Communications," in 2022 IEEE 11th Global Conference on Consumer Electronics (GCCE), 2022/10/18.</li>
          <li><strong>Kazushi Nakazawa</strong> and Kazuhiro Kondo, "Improvements to Non-Intrusive Intelligibility Prediction for Reverberant Speech," in 2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Tokyo, Japan, 2021/12, pp. 608-613.</li>
          <li>Toya Kitagawa, Kazuhiro Kondo, <strong>Kazushi Nakazawa</strong>, Yasushi Nakajima, "Quality Evaluation of Voice Synthesis Tools for Home Appliance Voice Communications," in 2021 IEEE 10th Global Conference on Consumer Electronics (GCCE), Kyoto, Japan, 2021/10/13.</li>
          <li><strong>Kazushi Nakazawa</strong> and Kazuhiro Kondo, "The estimation of non-referential speech intelligibility using DNN De-reverberation with SRMR value," in 2021 IEEE 10th Global Conference on Consumer Electronics (GCCE), Kyoto, Japan, 2021/10, pp. 518-519.</li>
          <li><strong>Kazushi Nakazawa</strong> and Kazuhiro Kondo, "On Non-Reference Speech Intelligibility Estimation Using DNN De-reverberation," in 2020 IEEE 9th Global Conference on Consumer Electronics (GCCE), Kobe, Japan, 2020/10, pp. 721-722.</li>
          <li><strong>Kazushi Nakazawa</strong> and Kazuhiro Kondo, "De-reverberation using CNN for non-reference reverberant speech intelligibility estimation," in Proceedings of the 23rd International Congress on Acoustics, Aachen, Germany, 2019/9, pp. 3098-3102.</li>
          <li><strong>Kazushi Nakazawa</strong> and Kazuhiro Kondo, "De-reverberation using DNN for Non-Reference Reverberant Speech Intelligibility Estimation," in 2018 IEEE 7th Global Conference on Consumer Electronics (GCCE), Nara, Japan, 2018/10, pp. 349-350.</li>
        </ol>
      </div>

      <div class="research-group">
        <h3>Domestic Conferences</h3>
        <ol>
          <li><strong>中澤和司</strong>, 近藤和弘，寺島裕貴，古川茂人，上村卓也, "複合音の非調和性に対する自然音分類に最適化された Deep neural networkの中間表現と心理実験の検出閾値の類似度分析", 日本音響学会2023年秋季研究発表会, 日本，名古屋, 2023/9.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "Audio Spectrogram Transformer を用いたNon-intrusive 音声了解度予測の検討", 日本音響学会2023年春季研究発表会, 日本，オンライン, 2023/3, pp. 543-546.</li>
          <li><strong>Kazushi Nakazawa</strong>, "A study of non-intrusive speech intelligibility estimation method for degraded speech using pseudo-references obtained by multiple speech enhancement DNNs," in The 19th IEEE TOWERS in Kansai, Osaka, Japan, 2022/10, B6.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "音声強調による複数の疑似レファレンスを用いた劣化音声に対するノンレファレンス音声了解度推定方法の検討", 日本音響2022年学会秋季研究発表会, 北海道，日本, 2022/9, pp. 469-472.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "CNN を用いたノンレファレンス音声了解度推定方法の検討", 日本音響学会2022年春季研究発表会, オンライン, 2022/3, pp. 763-764.</li>
          <li><strong>Kazushi Nakazawa</strong>, "A study of non-reference speech intelligibility estimation using CNN", in The 19th IEEE TOWERS in Sendai, Sendai, Japan, Sep 11, 2022, p. 6.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "ノンレファレンス音声了解度推定に向けた周波数重み付け特徴量の検討", 日本音響学会東北支部第4回東北地区音響学研究会, オンライン, 2021/11, pp. 4-5.</li>
          <li><strong>Kazushi Nakazawa</strong>, "Speech intelligibility estimation using speech enhancement for reverberant speech", in The 18th IEEE TOWERS, Online, 2021/11, A3-7.</li>
          <li>丸山翼，近藤和弘，<strong>中澤和司</strong>, "雪が音声了解度に与える影響-風速の測定方法の再検討-", 電気関係学会東北支部連合大会, 2021/8/26.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "残響劣化音に対する DNN を用いたノンレファレンス音声了解度推定 －音声の個人性による影響を考慮して－", 日本音響学会2021年春季研究発表会, オンライン, 2021/3, pp. 331-332.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "音声の個人性が残響劣化音に対する音声了解度に及ぼす影響の考察", 日本音響学会東北支部第3回東北地区音響学研究会, オンライン, 2020/11, p. 15.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "DNN を用いた残響環境下における音声了解度の推定のための了解度測定方法の検討", 日本音響学会2020年春季研究発表会, オンライン, 2020/2, pp. 537-538.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "残響劣化音に対する推定原音声を用いたノンレファレンス音声了解度推定", 日本音響学会2020年秋季研究発表会, オンライン, 2020/9, pp. 311-314.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "残響環境下における音声了解度の評価", 第2回 東北地区音響学研究会, 福島，日本, 2019/11, p. 13.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "CNNを用いた残響除去の検討", 日本音響学会2019年春季研究発表会, 東京，日本, 2019/3, pp. 403-404.</li>
          <li><strong>中澤和司</strong>，近藤和弘, "DNN を用いた残響除去における位相推定方法の検討", 第1回 東北地区音響学研究会, 秋田，日本, 2018/11, p. 11.</li>
        </ol>
      </div>
    </section>

    <section>
      <h2>Awards</h2>
      <ul class="item-list">

        <li>
          <span class="item-title">[2024/04/15] 電気学会東北支部 優秀論文賞</span>
        </li>
        <li>
          <span class="item-title">[2024/03] 日本音響学会 第150回（2023年秋季）研究発表会 学生優秀発表賞</span>
        </li>
        <li>
          <span class="item-title">[2021/12] 第4回東北地区音響学研究会 若手研究者優秀論文賞</span>
        </li>
        <li>
          <span class="item-title">[2020/10] IEEE GCCE 2020 Excellent Poster Award (Outstanding Prize)</span>
        </li>
        <li>
          <span class="item-title">[2018/3] 山形大学工学部 優秀学生賞</span>
        </li>
        </ul>
      </section>

  </main>
  <footer>
    &copy; 2024 <strong>Kazushi Nakazawa</strong>
  </footer>
</body>
</html>
